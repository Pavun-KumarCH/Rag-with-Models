{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOQFUNwNEJVLF8iU7RGABNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavun-KumarCH/Research-Notebooks/blob/main/Recommender_System_VDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender System with Vector Database"
      ],
      "metadata": {
        "id": "IqwDM0vqlALi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxOSF39YXNfb"
      },
      "outputs": [],
      "source": [
        "#@title requirements\n",
        "%pip install --q langchain openai pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dependencies\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from tqdm.auto import tqdm\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from IPython.display import Markdown, display\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Environment\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')"
      ],
      "metadata": {
        "id": "LKdawbasaJJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "#!wget -q --show-progress -O all-the-news-3.zip \"https://www.dropbox.com/scl/fi/wruzj2bwyg743d0jzd7ku/all-the-news-3.zip?rlkey=rgwtwpeznbdadpv3f01sznwxa&dl=1\"\n",
        "\n",
        "#!unzip all-the-news-3.zip"
      ],
      "metadata": {
        "id": "Ojjohu86a6OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v8ROr2vHbSaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('all-the-news-3.csv', 'r') as file:\n",
        "  header = file.readline()\n",
        "  print(header)"
      ],
      "metadata": {
        "id": "NfH5hzhQbJtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('all-the-news-3.csv', nrows = 99)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VQQWAqY_bcZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dlai_index_name(index_name):\n",
        "  openai_key = \"\"\n",
        "  try:\n",
        "    # For Google Colab\n",
        "    from google.colab import userdata\n",
        "    openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "  except ImportError:\n",
        "    # For Jupyter or other environments\n",
        "    openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    # Ensure openai_key is not empty\n",
        "  if not openai_key:\n",
        "    raise ValueError(\"OpenAI API key is missing.\")\n",
        "\n",
        "  return f'{index_name}-{openai_key[-36:].lower().replace(\"_\", \"-\")}'"
      ],
      "metadata": {
        "id": "dTZmt7ExcvFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup PineCone\n",
        "\n",
        "pinecone = Pinecone(api_key = PINECONE_API_KEY)\n",
        "\n",
        "INDEX_NAME = create_dlai_index_name(\"rsdl-ai\")\n",
        "\n",
        "# delete index if already exists\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "  pinecone.delete_index(INDEX_NAME)\n",
        "\n",
        "# create index\n",
        "pinecone.create_index(name = INDEX_NAME,\n",
        "                      dimension = 1536,\n",
        "                      metric = 'cosine',\n",
        "                      spec = ServerlessSpec(cloud = 'aws', region = 'us-east-1'))\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "index"
      ],
      "metadata": {
        "id": "sRJis-CFbhF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Embeddings of the News Titles\n",
        "openai_client = OpenAI(api_key = OPENAI_API_KEY)\n",
        "\n",
        "def get_embeddings(articles, model = \"text-embedding-ada-002\"):\n",
        "  return openai_client.embeddings.create(input = articles, model = model)"
      ],
      "metadata": {
        "id": "RvW_s3zTcgd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare the Embeddings and Upsert(upload) to Pinecone\n",
        "\n",
        "chunk_size = 400\n",
        "total_rows = 10000\n",
        "progress_bar = tqdm(total = total_rows)\n",
        "chunks = pd.read_csv('all-the-news-3.csv',\n",
        "                     chunksize = chunk_size,\n",
        "                     nrows = total_rows)\n",
        "\n",
        "chunk_num = 0\n",
        "for chunk in chunks:\n",
        "  titles = chunk['title'].tolist()\n",
        "  embeddings = get_embeddings(titles)\n",
        "  prepared = [{'id':str(chunk_num * chunk_size + i),\n",
        "               'values': embeddings.data[i].embedding,\n",
        "               'metadata': {'title': titles[i]},} for i in range(0, len(titles))]\n",
        "\n",
        "  chunk_num += 1\n",
        "  if len(prepared) >= 250:\n",
        "    index.upsert(vectors = prepared)\n",
        "    prepared = []\n",
        "  progress_bar.update(chunk_size)\n",
        "progress_bar.close()"
      ],
      "metadata": {
        "id": "aGXIklmOdc-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "B_w5GTBgfn9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Recommender System"
      ],
      "metadata": {
        "id": "mhiWZ8AHfr-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(pinecone_index, search_term, top_k = 5):\n",
        "  embed = get_embeddings([search_term]).data[0].embedding\n",
        "  res = pinecone_index.query(vector = embed,\n",
        "                             top_k = top_k,\n",
        "                             include_metadata = True)\n",
        "  return res"
      ],
      "metadata": {
        "id": "0b1IaKoBfrLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reco = get_recommendations(index, \"trump\")\n",
        "for r in reco.matches:\n",
        "  print(f'{r.score} : {r.metadata[\"title\"]}')"
      ],
      "metadata": {
        "id": "xi9NtXF6gkVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Embeddings of ALL News Content\n"
      ],
      "metadata": {
        "id": "wd9VOw0wjMaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "  pinecone.delete_index(name=INDEX_NAME)\n",
        "\n",
        "pinecone.create_index(name=INDEX_NAME, dimension=1536, metric='cosine',\n",
        "  spec=ServerlessSpec(cloud='aws', region='us-east-1'))\n",
        "articles_index = pinecone.Index(INDEX_NAME)"
      ],
      "metadata": {
        "id": "_P1slv_-gdq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(embeddings, title, prepared, embed_num):\n",
        "  for embedding in embeddings.data:\n",
        "    prepared.append({'id': str(embed_num),\n",
        "                     'values': embedding.embedding,\n",
        "                     'metadata': {'title':title}})\n",
        "    embed_num += 1\n",
        "    if len(prepared) >= 100:\n",
        "        articles_index.upsert(prepared)\n",
        "        prepared.clear()\n",
        "  return embed_num"
      ],
      "metadata": {
        "id": "7FCnThUtg-E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_data_rows_num = 100\n",
        "\n",
        "embed_num = 0 #keep track of embedding number for 'id'\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400,\n",
        "    chunk_overlap=20) # how to chunk each article\n",
        "prepped = []\n",
        "df = pd.read_csv('all-the-news-3.csv', nrows=news_data_rows_num)\n",
        "articles_list = df['article'].tolist()\n",
        "titles_list = df['title'].tolist()\n",
        "\n",
        "for i in range(0, len(articles_list)):\n",
        "    print(\".\",end=\"\")\n",
        "    art = articles_list[i]\n",
        "    title = titles_list[i]\n",
        "    if art is not None and isinstance(art, str):\n",
        "      texts = text_splitter.split_text(art)\n",
        "      embeddings = get_embeddings(texts)\n",
        "      embed_num1 = embed(embeddings, title, prepared, embed_num)"
      ],
      "metadata": {
        "id": "oXXibM-ghWRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Recommender System"
      ],
      "metadata": {
        "id": "8RH_aMztiGik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reco  = get_recommendations(articles_index, \"trump\")\n",
        "seen = {}\n",
        "for r in reco.matches:\n",
        "  title = r.metadata['title']\n",
        "  if title not in seen:\n",
        "    print(f'{r.score} : {title}')\n",
        "    seen[title] = '.'"
      ],
      "metadata": {
        "id": "JNtcYwP-iIDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}